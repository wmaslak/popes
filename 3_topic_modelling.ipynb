{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a5a2aa-3f7b-4533-8888-a29b4b589ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\wmasl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from helper_funs import *\n",
    "\n",
    "import numpy as np\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "with open(\"pickles/add_stopwords\", \"rb\") as fp:   # Unpickling\n",
    "    add_stopwords = pickle.load(fp)\n",
    "\n",
    "with open(\"pickles/add_characters_to_clean\", \"rb\") as fp:   # Unpickling\n",
    "    add_characters_to_clean = pickle.load(fp)\n",
    "    \n",
    "with open(\"pickles/selected_popes_names\", \"rb\") as fp:   # Unpickling\n",
    "    popes = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac37605-25a7-462e-b210-414436d85e45",
   "metadata": {},
   "source": [
    "## Building blocks of the modelling process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdfc01e6-49f4-4636-b6a8-e682f26595c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "df = get_df_of_enc(pope = 'all')\n",
    "# basic cleaning\n",
    "df['enc_text_clean'] = df['enc_text'].apply(lambda x:preprocess_text(x,True,True,False,\n",
    "                                           add_chars_to_clean = add_characters_to_clean , \n",
    "                                           add_stopwords = add_stopwords)\n",
    "                 )\n",
    "# another column also with tokenization and lemmatization\n",
    "df['enc_text_lem'] = df['enc_text_clean'].apply(lambda x:preprocess_text(text = x,tokenize = True, lemmatize = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a581116e-455d-4ab4-a9b2-4d740b8eb9ff",
   "metadata": {},
   "source": [
    "### Retrieving bi and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53f00831-e439-40a5-bf9f-e1e3db391e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bigrams.\n",
    "# Add bigrams and trigrams to docs (only those that appear 20 times or more).\n",
    "bigram = models.Phrases(df['enc_text_lem'], min_count=10, connector_words=models.phrases.ENGLISH_CONNECTOR_WORDS)\n",
    "for idx in range(len(df['enc_text_lem'])):\n",
    "    for token in bigram[df['enc_text_lem'][idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            df['enc_text_lem'][idx].append(token)\n",
    "trigram = models.Phrases(bigram[df['enc_text_lem']], min_count=5,connector_words=models.phrases.ENGLISH_CONNECTOR_WORDS )\n",
    "for idx in range(len(df['enc_text_lem'])):\n",
    "    for token in trigram[bigram[df['enc_text_lem'][idx]]]:\n",
    "        if token.count('_') == 2:\n",
    "            # Token is a trigram, add to document.\n",
    "            df['enc_text_lem'][idx].append(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c032e5-83f2-4c10-a351-e4f3ff5829bc",
   "metadata": {},
   "source": [
    "### Creating and saving corpus and dictionary objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af5b8b3e-6569-4773-91aa-5edb7dcbfdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary and corpus \n",
    "dictionary = corpora.Dictionary(df['enc_text_lem'])\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.7)\n",
    "corpus = [dictionary.doc2bow(text) for text in df['enc_text_lem']]\n",
    "# save created objects\n",
    "pickle.dump(corpus, open('pickles/corpus', 'wb'))\n",
    "dictionary.save('pickles/dictionary.gensim')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43059ac-9f58-4d3e-b7a5-d4e728476ce9",
   "metadata": {},
   "source": [
    "### Fitting LDA model with specified number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2eb8722-2a53-416a-a3d7-df56bed91f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 8\n",
    "ldamodel = models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)\n",
    "ldamodel.save('models/model_lda_0.gensim')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67c97787-d7a9-4f07-ba10-629ce32619ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.007*\"social\" + 0.005*\"country\" + 0.005*\"principle\" + 0.004*\"pius\" + 0.004*\"labor\"')\n",
      "(1, '0.009*\"council\" + 0.008*\"son\" + 0.007*\"mystery\" + 0.007*\"holy_spirit\" + 0.006*\"jn\"')\n",
      "(2, '0.009*\"priest\" + 0.008*\"body\" + 0.005*\"apostle\" + 0.005*\"sacrifice\" + 0.004*\"jesus_christ\"')\n",
      "(3, '0.007*\"law\" + 0.005*\"civil\" + 0.005*\"action\" + 0.004*\"liberty\" + 0.004*\"marriage\"')\n",
      "(4, '0.035*\"missionary\" + 0.021*\"mission\" + 0.014*\"activity\" + 0.010*\"gospel\" + 0.009*\"community\"')\n",
      "(5, '0.011*\"mother\" + 0.009*\"mary\" + 0.008*\"virgin\" + 0.006*\"scripture\" + 0.005*\"bless\"')\n",
      "(6, '0.010*\"social\" + 0.009*\"development\" + 0.005*\"economic\" + 0.005*\"person\" + 0.005*\"country\"')\n",
      "(7, '0.012*\"unity\" + 0.009*\"brother\" + 0.006*\"council\" + 0.006*\"roman\" + 0.005*\"apostolic_see\"')\n"
     ]
    }
   ],
   "source": [
    "topics = ldamodel.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889d964a-7253-4f72-bc82-98aad1835798",
   "metadata": {},
   "source": [
    "### Generating visualization of the fitted LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef12f1ec-1792-4011-ba71-4df29b6f7fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load('pickles/dictionary.gensim')\n",
    "corpus = pickle.load(open('pickles/corpus', 'rb'))\n",
    "lda = models.ldamodel.LdaModel.load('models/model_lda_0.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bee21f29-a7b5-404f-acab-2cc7f0d5ccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wmasl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lda_display = pyLDAvis.gensim_models.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.save_html(lda_display, 'ldavis/test2.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1bf61b-0b8e-4b71-843e-d3d81a6d71ea",
   "metadata": {},
   "source": [
    "## The main modelling function (everything above packed in one function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4c406b-eb80-4c18-9766-74d9259b84ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that does all the above at one call \n",
    "def train_lda(df,\n",
    "              preprocess=True,\n",
    "              render_html=False,\n",
    "              save_model=True,\n",
    "              return_corp_and_dict=False,\n",
    "              model_name=dt.strftime(dt.now(), '%d_%m_%H_%M_%S'),\n",
    "              kwargs_for_preprocess={    'cleanup' : True,\n",
    "                                         'stopwords'  : True,\n",
    "                                         'tokenize'  : True,\n",
    "                                         'lemmatize'  : True,\n",
    "                                         'add_stopwords'  : add_stopwords,\n",
    "                                         'add_chars_to_clean'  : add_characters_to_clean,\n",
    "                                    },\n",
    "              kwargs_for_lda={  'k':5,\n",
    "                                'passes':15\n",
    "                             },\n",
    "              add_kwargs={         'min_bigram' : 10,\n",
    "                                   'min_trigram' : 5,\n",
    "                                   'no_below' : 5,\n",
    "                                   'no_above' : 0.7\n",
    "                                }\n",
    "             ):\n",
    "    # in case of providing a subset of df\n",
    "    df = df.reset_index()\n",
    "    if preprocess:\n",
    "        # preprocess\n",
    "        df['enc_text_lem'] = df['enc_text'].apply(lambda x:preprocess_text( text = x,\n",
    "                                                                            cleanup            = kwargs_for_preprocess['cleanup'],\n",
    "                                                                            stopwords          = kwargs_for_preprocess['stopwords'],\n",
    "                                                                            tokenize           = kwargs_for_preprocess['tokenize'],\n",
    "                                                                            lemmatize          = kwargs_for_preprocess['lemmatize'],\n",
    "                                                                            add_stopwords      = kwargs_for_preprocess['add_stopwords'],\n",
    "                                                                            add_chars_to_clean = kwargs_for_preprocess['add_chars_to_clean'],))\n",
    "\n",
    "\n",
    "    # Add bigrams and trigrams to docs (only those that appear given number of times or more).\n",
    "    bigram = models.Phrases(df['enc_text_lem'], min_count=add_kwargs['min_bigram'], connector_words=models.phrases.ENGLISH_CONNECTOR_WORDS)\n",
    "    for idx in range(len(df['enc_text_lem'])):\n",
    "        for token in bigram[df['enc_text_lem'][idx]]:\n",
    "            if '_' in token:\n",
    "                # Token is a bigram, add to document.\n",
    "                df['enc_text_lem'][idx].append(token)\n",
    "    trigram = models.Phrases(bigram[df['enc_text_lem']], min_count=add_kwargs['min_trigram'],connector_words=models.phrases.ENGLISH_CONNECTOR_WORDS )\n",
    "    for idx in range(len(df['enc_text_lem'])):\n",
    "        for token in trigram[bigram[df['enc_text_lem'][idx]]]:\n",
    "            if token.count('_') == 2:\n",
    "                # Token is a trigram, add to document.\n",
    "                df['enc_text_lem'][idx].append(token)\n",
    "                \n",
    "                \n",
    "    # make dictionary and corpus \n",
    "    dictionary = corpora.Dictionary(df['enc_text_lem'])\n",
    "    dictionary.filter_extremes(no_below=add_kwargs['no_below'], no_above=add_kwargs['no_above'])\n",
    "    corpus = [dictionary.doc2bow(text) for text in df['enc_text_lem']]\n",
    "   \n",
    "    \n",
    "    # fit and save model\n",
    "    ldamodel = models.ldamodel.LdaModel(corpus, num_topics = kwargs_for_lda['k'], id2word=dictionary, passes=kwargs_for_lda['passes'])\n",
    "\n",
    "    if save_model:\n",
    "        print(f\"Saving model as {'model_'+model_name+'.gensim'}\")\n",
    "        # save created objects\n",
    "        pickle.dump(corpus, open('pickles/corpus_'+model_name, 'wb'))\n",
    "        dictionary.save('pickles/dictionary_'+model_name+'.gensim')\n",
    "        ldamodel.save('models/model_'+model_name+'.gensim')\n",
    "    \n",
    "    # render html\n",
    "    if render_html:\n",
    "        lda_display = pyLDAvis.gensim_models.prepare(ldamodel, corpus, dictionary, sort_topics=False)\n",
    "        pyLDAvis.save_html(lda_display, 'ldavis/topics_for_model_'+model_name+'.html')\n",
    "    if return_corp_and_dict:\n",
    "        return(ldamodel,corpus,dictionary)\n",
    "    else:\n",
    "        return(ldamodel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca64d1a8-d758-4bb6-95c9-fb0887defdbd",
   "metadata": {},
   "source": [
    "### Function to compute coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b36b056-eb07-42d6-a0e7-e16a79fa402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to compute coherence\n",
    "\n",
    "\n",
    "def compute_coherence_values(obj, # df, model, or string containing model name\n",
    "                             k=5 ,no_below=0, no_above=1,coh_measure ='u_mass',corp = None, dictio = None): \n",
    "    \n",
    "    if isinstance(obj,pd.DataFrame):\n",
    "        dictionary = corpora.Dictionary(data)\n",
    "        dictionary.filter_extremes(no_below=no_below, no_above=no_above)\n",
    "        corpus = [dictionary.doc2bow(text) for text in data]\n",
    "        print('Fitting LDA...')\n",
    "        lda_model = models.ldamodel.LdaModel(corpus, num_topics=k, id2word=dictionary, passes=15)\n",
    "        coherence_model_lda = CoherenceModel(model=lda_model,corpus = corpus, dictionary=dictionary, coherence=coh_measure)\n",
    "        \n",
    "    elif isinstance(obj,models.ldamodel.LdaModel):\n",
    "        dictionary = dictio\n",
    "        corpus = corp\n",
    "        print('Calculating coherence...')\n",
    "        lda_model = obj\n",
    "        coherence_model_lda = CoherenceModel(model=lda_model,corpus = corpus, dictionary=dictionary, coherence=coh_measure)\n",
    "        \n",
    "    elif isinstance(obj,str):\n",
    "        model_name = obj\n",
    "        print(f\"Loading model from {'models/model_'+model_name+'.gensim'} ...\")\n",
    "        dictionary = corpora.Dictionary.load('pickles/dictionary_'+model_name+'.gensim')\n",
    "        corpus = pickle.load(open('pickles/corpus_'+model_name, 'rb'))\n",
    "        lda_model = models.ldamodel.LdaModel.load('models/model_'+model_name+'.gensim')\n",
    "        print('Calculating coherence...')\n",
    "        coherence_model_lda = CoherenceModel(model=lda_model,corpus = corpus, dictionary=dictionary, coherence=coh_measure)\n",
    "        \n",
    "    return coherence_model_lda.get_coherence()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d666ef5-3e05-41aa-8d0f-15e15892ad6f",
   "metadata": {},
   "source": [
    "### Function to plot correlation heatmap between topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "35a7255e-27ef-45c1-9922-3135cbcd637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_difference(lda_fst,distance='jaccard',num_words=20 ,title=\"Topic difference\"):\n",
    "    \"\"\"Helper function to plot difference between models.\n",
    "\n",
    "    Uses matplotlib as the backend.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    mdiff, annotation = lda_fst.diff(lda_fst, distance='jaccard', num_words=50)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(18, 14))\n",
    "    data = ax.imshow(mdiff, cmap='RdBu_r', origin='lower')\n",
    "    plt.title(title)\n",
    "    plt.colorbar(data)\n",
    "    return(mdiff,annotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5c324b-cb64-4810-bbce-0e83a1ec801b",
   "metadata": {},
   "source": [
    "### Function that calculates **distance to ideal** evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0a7e581-09ba-4d7e-9a61-f608ba356c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_far_from_ideal(obj,distance_lst = ['kullback_leibler', 'hellinger', 'jaccard', 'jensen_shannon'],normalize = True):\n",
    "    \n",
    "    dist_to_ideal = {}\n",
    "    if isinstance(obj,models.ldamodel.LdaModel):\n",
    "        \n",
    "        for d in distance_lst:\n",
    "            \n",
    "            lda = obj\n",
    "            mdiff,ann = lda.diff(lda)\n",
    "            n_topics = mdiff.shape[0]\n",
    "            ideal_matrix = np.ones([n_topics,n_topics])\n",
    "            np.fill_diagonal(ideal_matrix, 0.)\n",
    "            dist_to_ideal[d] = np.linalg.norm(mdiff - ideal_matrix)\n",
    "            if normalize:\n",
    "                dist_to_ideal[d] = dist_to_ideal[d] / n_topics\n",
    "            avg_dist = np.array(list(dist_to_ideal.values())).mean()\n",
    "        return(dist_to_ideal,avg_dist)\n",
    "    else:\n",
    "        return(f'Provided object of type {type(obj)}, instead of LdaModel')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fcfc77-1f66-4797-b80f-d4adf4181fad",
   "metadata": {},
   "source": [
    "## Performing gridsearches for tunung parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7eb4dd0d-fda2-4528-b227-0d9efaecd1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid length: 9\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "no_belows = [20]\n",
    "no_aboves = [0.7]\n",
    "min_bigrams = [5,20,30]\n",
    "min_trigrams = [3,10,20]\n",
    "ks = [10]\n",
    "grid_grams = [[b,a,k,bi,tri] for b in no_belows for a in no_aboves for k in ks for bi in min_bigrams for tri in min_trigrams]\n",
    "print(f'Grid length: {len(grid_grams)}')\n",
    "def lda_gs(grid,df):\n",
    "    import time\n",
    "    data_dict = {}\n",
    "    elapsed_times=[]\n",
    "    data_dict['K'] = []\n",
    "    data_dict['no_below'] = []\n",
    "    data_dict['no_above'] = []\n",
    "    data_dict['min_bigram']  = []\n",
    "    data_dict['min_trigram'] = []\n",
    "    data_dict['coherence_score'] = []\n",
    "    data_dict['dist_to_ideal'] = []\n",
    "    \n",
    "    for i,params in enumerate(grid):\n",
    "        no_below, no_above, k, bi, tri = params\n",
    "        print(f\"Processing for params no_below = {no_below}, no_above = {no_above}, k = {k}, min_bigram = {bi}, min_trigram = {tri} ({i+1}/{len(grid)})...\")\n",
    "      \n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "\n",
    "        data_dict['no_below'].append(no_below)\n",
    "        data_dict['no_above'].append(no_above)\n",
    "        data_dict['min_bigram'].append(bi)\n",
    "        data_dict['min_trigram'].append(tri)\n",
    "        data_dict['K'].append(k)\n",
    "        # train LDA\n",
    "        print('Fitting...')\n",
    "        model,corpus,dictionary = train_lda(df['enc_text_lem'],\n",
    "                                              preprocess=False,\n",
    "                                              render_html=False,\n",
    "                                              save_model=False,\n",
    "                                              return_corp_and_dict=True,\n",
    "                                              kwargs_for_lda={  'k':k,\n",
    "                                                                'passes':15\n",
    "                                                             },\n",
    "                                              add_kwargs={         'min_bigram' : bi,\n",
    "                                                                   'min_trigram' : tri,\n",
    "                                                                   'no_below' : no_below,\n",
    "                                                                   'no_above' : no_above\n",
    "                                                                }\n",
    "                                                 )\n",
    "        print('Evaluating...')\n",
    "        cs = compute_coherence_values(model,k = k ,corp = corpus, dictio=dictionary)\n",
    "        data_dict['coherence_score'].append(cs)\n",
    "        _,a_dist = how_far_from_ideal(model)\n",
    "        data_dict['dist_to_ideal'].append(a_dist)\n",
    "        print(f\"...coherence score: {cs} ; avg. distance to ideal: {a_dist}\")\n",
    "        end = time.time()\n",
    "        elapsed_times.append(end - start)\n",
    "        avg_time=np.mean(elapsed_times)\n",
    "        estimated_time = (len(grid) - i-1)*avg_time\n",
    "        print(f'...estimated time till end: {estimated_time/60} minutes ...')\n",
    "    df_res = pd.DataFrame(data_dict)\n",
    "    return(df_res)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d38933-4c32-4c9a-9d83-d213690ee113",
   "metadata": {},
   "source": [
    "#### Tuning min_bigram and min_trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "949c5d77-c2e2-44df-a351-9f8cf8e32c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df_of_enc(pope = 'all')\n",
    "df['enc_text_lem'] = df['enc_text'].apply(lambda x:preprocess_text(x,True,True,True,True,\n",
    "                                           add_chars_to_clean = add_characters_to_clean , \n",
    "                                           add_stopwords = add_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2b1772-551d-4ed3-a0c6-d8cbf41bfba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_grams = lda_gs(grid_grams,df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d50ad199-4a7f-4d55-b2f6-12af9f1f5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grams.to_csv('csv/df_grams.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d98a5cf-414f-4c1b-8be9-56bc9be258eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='min_bigram'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_grams.sort_values('dist_to_ideal', ascending = False).plot(x='min_bigram',y='coherence_score', kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237a66a5-ce3b-4c33-8fee-72318c749f3f",
   "metadata": {},
   "source": [
    "Better both coherence and distance to ideal when we are less restrictive with bigrams and trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f61ecf-ac89-4576-b8b3-5331b4f99f9a",
   "metadata": {},
   "source": [
    "#### Tuning no_below and no_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32134599-a616-4371-b239-a6959792b3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grid search\n",
    "no_belows = [10,20,40]\n",
    "no_aboves = [0.7]\n",
    "min_bigrams = [20]\n",
    "min_trigrams = [15]\n",
    "ks = [10]\n",
    "grid_extremes = [[b,a,k,bi,tri] for b in no_belows for a in no_aboves for k in ks for bi in min_bigrams for tri in min_trigrams]\n",
    "len(grid_extremes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30f92c67-82ee-4a12-af90-b75c5e5adf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for params no_below = 10, no_above = 0.7, k = 10, min_bigram = 20, min_trigram = 15 (1/3)...\n",
      "Fitting...\n",
      "Evaluating...\n",
      "Calculating coherence...\n",
      "...coherence score: -0.540549297086317 ; avg. distance to ideal: 0.4088763745561431\n",
      "...estimated time till end: 1.6780441602071126 minutes ...\n",
      "Processing for params no_below = 20, no_above = 0.7, k = 10, min_bigram = 20, min_trigram = 15 (2/3)...\n",
      "Fitting...\n",
      "Evaluating...\n",
      "Calculating coherence...\n",
      "...coherence score: -0.5923089049996124 ; avg. distance to ideal: 0.3950420837532934\n",
      "...estimated time till end: 0.8174088517824809 minutes ...\n",
      "Processing for params no_below = 40, no_above = 0.7, k = 10, min_bigram = 20, min_trigram = 15 (3/3)...\n",
      "Fitting...\n",
      "Evaluating...\n",
      "Calculating coherence...\n",
      "...coherence score: -0.6209863000497762 ; avg. distance to ideal: 0.43615355105367104\n",
      "...estimated time till end: 0.0 minutes ...\n"
     ]
    }
   ],
   "source": [
    "df_extremes = lda_gs(grid_extremes,df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59fdba33-6779-4f5b-9a10-dac1638d8ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extremes.to_csv('csv/df_extremes_below.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1994a3-01d7-4cb2-b67c-03cd7ef1154b",
   "metadata": {},
   "source": [
    "### Tuninng number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b11d9c67-97db-4cd4-9abf-fea8700a62ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing for params no_below = 20, no_above = 0.7, k = 8, min_bigram = 20, min_trigram = 10 (1/3)...\n",
      "Fitting...\n",
      "Evaluating...\n",
      "Calculating coherence...\n",
      "...coherence score: -0.9338019028649018 ; avg. distance to ideal: 0.4264185810975575\n",
      "...estimated time till end: 1.5412134250005087 minutes ...\n",
      "Processing for params no_below = 20, no_above = 0.7, k = 10, min_bigram = 20, min_trigram = 10 (2/3)...\n",
      "Fitting...\n",
      "Evaluating...\n",
      "Calculating coherence...\n",
      "...coherence score: -1.0313382541681873 ; avg. distance to ideal: 0.45986824499428114\n",
      "...estimated time till end: 0.8661614934603373 minutes ...\n",
      "Processing for params no_below = 20, no_above = 0.7, k = 15, min_bigram = 20, min_trigram = 10 (3/3)...\n",
      "Fitting...\n",
      "Evaluating...\n",
      "Calculating coherence...\n",
      "...coherence score: -1.1005325595987339 ; avg. distance to ideal: 0.4815155125113625\n",
      "...estimated time till end: 0.0 minutes ...\n"
     ]
    }
   ],
   "source": [
    "# grid search\n",
    "no_belows = [20]\n",
    "no_aboves = [0.7]\n",
    "min_bigrams = [20]\n",
    "min_trigrams = [10]\n",
    "ks = [8,10,15]\n",
    "grid_topics = [[b,a,k,bi,tri] for b in no_belows for a in no_aboves for k in ks for bi in min_bigrams for tri in min_trigrams]\n",
    "len(grid_topics)\n",
    "\n",
    "df_topics = lda_gs(grid_topics,df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "524807f3-53a8-4b6a-8df6-53fb4a6af122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>no_below</th>\n",
       "      <th>no_above</th>\n",
       "      <th>min_bigram</th>\n",
       "      <th>min_trigram</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>dist_to_ideal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.933802</td>\n",
       "      <td>0.426419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.031338</td>\n",
       "      <td>0.459868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>-1.100533</td>\n",
       "      <td>0.481516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    K  no_below  no_above  min_bigram  min_trigram  coherence_score  \\\n",
       "0   8        20       0.7          20           10        -0.933802   \n",
       "1  10        20       0.7          20           10        -1.031338   \n",
       "2  15        20       0.7          20           10        -1.100533   \n",
       "\n",
       "   dist_to_ideal  \n",
       "0       0.426419  \n",
       "1       0.459868  \n",
       "2       0.481516  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_topics.to_csv('csv/df_topics.csv')\n",
    "df_topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe009d6f-abfc-4069-ad49-0d8c3c2bb9db",
   "metadata": {},
   "source": [
    "# Fitting final LDA on corpus of encyclicals of all popes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "243b754f-37d3-43ea-ba07-48261a12b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model as model_ALL_POPES.gensim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wmasl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "# final model for all popes\n",
    "model,corpus,dictionary = train_lda(df['enc_text_lem'],\n",
    "              preprocess=False,\n",
    "              render_html=True,\n",
    "              save_model=True,\n",
    "              return_corp_and_dict=True,\n",
    "              model_name=\"ALL_POPES\",\n",
    "              kwargs_for_preprocess={    'cleanup' : True,\n",
    "                                         'stopwords'  : True,\n",
    "                                         'tokenize'  : True,\n",
    "                                         'lemmatize'  : True,\n",
    "                                         'add_stopwords'  : add_stopwords,\n",
    "                                         'add_chars_to_clean'  : add_characters_to_clean,\n",
    "                                    },\n",
    "              kwargs_for_lda={  'k':8,\n",
    "                                'passes':15\n",
    "                             },\n",
    "              add_kwargs={         'min_bigram' : 5,\n",
    "                                   'min_trigram' : 3,\n",
    "                                   'no_below' : 20,\n",
    "                                   'no_above' : 0.7\n",
    "                                }\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba263362-500a-44bb-bf33-ee7e53735f69",
   "metadata": {},
   "source": [
    "## Evaluating result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b84b414-b7c2-45f3-8951-775bf60bae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load('pickles/dictionary_ALL_POPES.gensim')\n",
    "corpus = pickle.load(open('pickles/corpus_ALL_POPES', 'rb'))\n",
    "lda = models.ldamodel.LdaModel.load('models/model_ALL_POPES.gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "010bda64-9adf-4cdd-9a89-0b3ea0716693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating coherence...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.528560939497797"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_coherence_values(lda,corp=corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d037940e-4c51-442a-b461-267cc21eaacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance to ideal is: 0.38661726117421125\n"
     ]
    }
   ],
   "source": [
    "_,dti = how_far_from_ideal(lda)\n",
    "print(f'The distance to ideal is: {dti}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "764fd9cd-b64c-48fe-9fbb-51deee95f0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1008 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "diff,ann = plot_difference(lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a5c813-f7fd-4558-b78c-ba764437469d",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "### Fitting LDA for each pope individually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5ba043-d907-4db1-b743-fd563bfde7c8",
   "metadata": {},
   "source": [
    "We will also look at each pope separately and try model topics contained within encyclicals of each pope individually.\n",
    "\n",
    "So for popes who wrote short encyclicals K should be roughly equal to the number of encyclicals, while for those who wrote long ones it can be more than that\n",
    "\n",
    "* $N_{topics} \\propto N_{encyclicals}$\n",
    "* $N_{topics} \\propto (avg.length_{encyclicals.of.pope} - avg.length_{all.encyclicals})^+$  \n",
    "* $N_{topics} \\geq  N_{encyclicals},$\n",
    "\n",
    "where we denote $(x)^+ := \\max(0,x) $ \n",
    "\n",
    "$$ N_{topics} = N_{encyclicals} + \\frac{(avg.length_{encyclicals.of.pope} - avg.length_{all.encyclicals})^+}{\\sigma_{all.encyclicals}}, $$ \n",
    "where $\\sigma_{all.encyclicals}$ is the standard deviation of lengths of all encyclicals. In words, we set the number of topics to the number of encyclicals and we add \"bonus\" topics for every standard deviation above the average of all popes in sample.\n",
    "\n",
    "While this formula seems appealing it unfortunately yielded very high number of topics for some of the popes. While a high number itself does not cause too much of a problem, it is troublesome for visualization and human inspection. Therefore I decided to cap the number of topics to 20, so the final formula is:\n",
    "$$N_{topics.final} = \\min(20,N_{topics})$$\n",
    "\n",
    "We also set a little bit more restrictive constraints on the words to filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54854fbf-715b-4399-a377-2957937b620c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model as model_Pius XI.gensim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wmasl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model as model_Benedict XV.gensim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wmasl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model as model_Pius X.gensim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wmasl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model as model_Leo XIII.gensim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\wmasl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "avg_len_all = np.median(df.enc_text.apply(lambda x: len(x)))\n",
    "sd_len_all = np.std(df.enc_text.apply(lambda x: len(x)))\n",
    "mult = 2\n",
    "for pope in popes[6:]:\n",
    "    df_pope = df[df['popes'] == pope].reset_index().copy()\n",
    "    n_enc = len(df_pope)\n",
    "    \n",
    "    df_pope['len'] = df_pope.enc_text.apply(lambda x: len(x))\n",
    "    avg_len_pope = np.mean(df_pope.len)\n",
    "    k = n_enc + mult*np.floor(max(avg_len_pope-avg_len_all,0)/sd_len_all)\n",
    "    k = min(20,k)\n",
    "    _,__,___ = train_lda(df['enc_text_lem'],\n",
    "              preprocess=False,\n",
    "              render_html=True,\n",
    "              save_model=True,\n",
    "              return_corp_and_dict=True,\n",
    "              model_name=pope,\n",
    "              kwargs_for_preprocess={    'cleanup' : True,\n",
    "                                         'stopwords'  : True,\n",
    "                                         'tokenize'  : True,\n",
    "                                         'lemmatize'  : True,\n",
    "                                         'add_stopwords'  : add_stopwords,\n",
    "                                         'add_chars_to_clean'  : add_characters_to_clean,\n",
    "                                    },\n",
    "              kwargs_for_lda={  'k':k,\n",
    "                                'passes':15\n",
    "                             },\n",
    "              add_kwargs={         'min_bigram' : 20,\n",
    "                                   'min_trigram' : 15,\n",
    "                                   'no_below' : 10,\n",
    "                                   'no_above' : 0.6\n",
    "                                }\n",
    "             )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
